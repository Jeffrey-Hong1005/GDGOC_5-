{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ConversationKGMemory\n",
    "\n",
    "지식 그래프의 힘을 활용하여 정보를 저장하고 불러옵니다.\n",
    "\n",
    "이를 통해 모델이 서로 다른 개체 간의 관계를 이해하는 데 도움을 주고, 복잡한 연결망과 역사적 맥락을 기반으로 대응하는 능력을 향상시킵니다.\n",
    "\n",
    "## history -> 문장 전체 저장, 의미를 구조적으로 이해하지 못함 = 문장이 어떤 관계를 갖는지 인식하지 못함\n",
    "## KG -> 문장 내부의 구조적 관계와 의미를 저장 (subject, relation, object 등등)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jeffr\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-kr-SGRq4Tjy-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "kg_store = []\n",
    "\n",
    "# 3) 매우 단순한 KG 추출기\n",
    "def extract_triplet(text: str): #무엇을 기억할지 결정하는 규칙\n",
    "    \n",
    "    #문장에서 (주어,관계,객체) 추출 – 구버전 KGMemory 기능의 최소 대체.\n",
    "    #복잡한 NLP 사용하지 않고 코드가 원하는 기능만 수행.\n",
    "    \n",
    "    triples = []\n",
    "\n",
    "    # Pangyo 에 거주중인 김셜리\n",
    "    if \"거주\" in text and \"김셜리\" in text:\n",
    "        triples.append({\"subject\": \"김셜리\", \"relation\": \"거주지\", \"object\": \"Pangyo\"})\n",
    "\n",
    "    # 신입 디자이너\n",
    "    if \"신입 디자이너\" in text and \"김셜리\" in text:\n",
    "        triples.append({\"subject\": \"김셜리\", \"relation\": \"직업\", \"object\": \"신입 디자이너\"})\n",
    "\n",
    "    return triples\n",
    "\n",
    "\n",
    "def save_context(input, output):\n",
    "    #ConversationKGMemory.save_context 대체\n",
    "    text = input.get(\"input\", \"\")\n",
    "    triples = extract_triplet(text)\n",
    "    for t in triples:\n",
    "        kg_store.append(t)\n",
    "\n",
    "\n",
    "def load_memory_variables(query: dict):\n",
    "    #ConversationKGMemory.load_memory_variables 대체\n",
    "    # 단순히 KG 전체를 반환 (구버전의 반환 구조와 동일)\n",
    "    return {\"history\": json.dumps(kg_store, ensure_ascii=False)}\n",
    "\n",
    "\n",
    "save_context( # 전에 대체되었던 sav_context는 메소드고 이건 함수\n",
    "    {\"input\": \"이쪽은 Pangyo 에 거주중인 김셜리씨 입니다.\"},\n",
    "    {\"output\": \"김셜리씨는 누구시죠?\"}\n",
    ")\n",
    "\n",
    "save_context(\n",
    "    {\"input\": \"김셜리씨는 우리 회사의 신입 디자이너입니다.\"},\n",
    "    {\"output\": \"만나서 반갑습니다.\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 대화 지식 그래프 메모리 -----\n",
      "{'history': '[{\"subject\": \"김셜리\", \"relation\": \"거주지\", \"object\": \"Pangyo\"}, {\"subject\": \"김셜리\", \"relation\": \"직업\", \"object\": \"신입 디자이너\"}]'}\n"
     ]
    }
   ],
   "source": [
    "result = load_memory_variables({\"input\": \"김셜리씨는 누구입니까?\"})\n",
    "\n",
    "print(\"----- 대화 지식 그래프 메모리 -----\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain 에 메모리 활용하기\n",
    "\n",
    "`ConversationChain` 에 `ConversationKGMemory` 를 메모리로 지정하여 대화를 나눈 후 memory 를 확인해 보도록 하겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "죄송하지만, 제공된 정보에는 김셜리씨에 대한 내용이 없습니다. 김셜리씨에 대해 더 알고 싶으시면 다른 출처를 참고해 보시기 바랍니다.\n",
      "[HumanMessage(content='김셜리씨는 누구입니까?', additional_kwargs={}, response_metadata={}), AIMessage(content='죄송하지만, 제공된 정보에는 김셜리씨에 대한 내용이 없습니다. 김셜리씨에 대해 더 알고 싶으시면 다른 출처를 참고해 보시기 바랍니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 110, 'total_tokens': 150, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CcVO2vsgGYuWBi0BwyVPyIEO0YeX9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--ee2a92d5-7406-45a7-9bf1-c02502416b80-0', usage_metadata={'input_tokens': 110, 'output_tokens': 40, 'total_tokens': 150, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "template = \"\"\"The following is a friendly conversation between a human and an AI. \n",
    "The AI is talkative and provides lots of specific details from its context. \n",
    "If the AI does not know the answer to a question, it truthfully says it does not know. \n",
    "The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n",
    "\n",
    "Relevant Information:\n",
    "\n",
    "{history}\n",
    "\n",
    "Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "# 3. 최신 버전 Prompt 형태로 변환\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# 4. history 메모리 (ConversationKGMemory 대체)\n",
    "history = InMemoryChatMessageHistory()\n",
    "\n",
    "# 5. ConversationChain 대체\n",
    "conversation_with_kg = RunnableWithMessageHistory(\n",
    "    prompt | llm,\n",
    "    lambda session_id: history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# 사용 예시\n",
    "\n",
    "user_question = \"김셜리씨는 누구입니까?\"\n",
    "\n",
    "response = conversation_with_kg.invoke(\n",
    "    {\"input\": user_question},\n",
    "    config={\"configurable\": {\"session_id\": \"session1\"}}\n",
    ")\n",
    "\n",
    "print(response.content)\n",
    "print(history.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫 번째 대화를 시작합니다. 간단한 인물에 대한 정보를 제공해 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='김셜리씨는 누구입니까?', additional_kwargs={}, response_metadata={}), AIMessage(content='죄송하지만, 제공된 정보에는 김셜리씨에 대한 내용이 없습니다. 김셜리씨에 대해 더 알고 싶으시면 다른 출처를 참고해 보시기 바랍니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 110, 'total_tokens': 150, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CcVO2vsgGYuWBi0BwyVPyIEO0YeX9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--ee2a92d5-7406-45a7-9bf1-c02502416b80-0', usage_metadata={'input_tokens': 110, 'output_tokens': 40, 'total_tokens': 150, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content=\"My name is Teddy. Shirley is a coworker of mine, and she's a new designer at our company.\", additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, Teddy님! Shirley씨가 당신의 동료이자 회사의 새로운 디자이너라고 하셨네요. Shirley씨와 함께 일하는 것이 즐거우시길 바랍니다. 혹시 Shirley씨와 관련해서 더 궁금한 점이나 도움이 필요하시면 언제든지 말씀해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 65, 'prompt_tokens': 525, 'total_tokens': 590, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CcVOFvpxIWzwzahMf3KiCd1E2BC4n', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--3916e570-f216-45b8-83a3-4edf8e9e764e-0', usage_metadata={'input_tokens': 525, 'output_tokens': 65, 'total_tokens': 590, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content='Who is Shirley?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Shirley is your coworker and a new designer at your company, as you mentioned. If you'd like to share more about her or need any help related to Shirley, feel free to ask!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 952, 'total_tokens': 992, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CcVOWjPl1EA9vPbUW5U7vIBwTIV6p', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--923694ab-4e8f-4313-a7e8-6a93d936390e-0', usage_metadata={'input_tokens': 952, 'output_tokens': 40, 'total_tokens': 992, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), HumanMessage(content=\"My name is Teddy. Shirley is a coworker of mine, and she's a new designer at our company.\", additional_kwargs={}, response_metadata={}), AIMessage(content='안녕하세요, Teddy님! Shirley씨는 당신의 동료이자 회사의 새로운 디자이너라고 하셨죠. Shirley씨와 함께 일하는 경험이 즐거우시길 바랍니다. Shirley씨에 대해 더 궁금한 점이나 도움이 필요하시면 언제든지 말씀해 주세요!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 1368, 'total_tokens': 1431, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-mini-2025-04-14', 'system_fingerprint': 'fp_4c2851f862', 'id': 'chatcmpl-CcVP9b5Mh2CDyPjwWc4DLeX4pew9X', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5ff6c1e6-b5e4-44b8-8485-8703d6d5fd72-0', usage_metadata={'input_tokens': 1368, 'output_tokens': 63, 'total_tokens': 1431, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "안녕하세요, Teddy님! Shirley씨는 당신의 동료이자 회사의 새로운 디자이너라고 하셨죠. Shirley씨와 함께 일하는 경험이 즐거우시길 바랍니다. Shirley씨에 대해 더 궁금한 점이나 도움이 필요하시면 언제든지 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# conversation_with_kg.predict(\n",
    "#     input=\"My name is Teddy. Shirley is a coworker of mine, and she's a new designer at our company.\"\n",
    "# )\n",
    "\n",
    "response = conversation_with_kg.invoke(\n",
    "    {\"input\": \"My name is Teddy. Shirley is a coworker of mine, and she's a new designer at our company.\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session1\"}}\n",
    ")\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shirley 라는 사람에 대한 질문을 진행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shirley is your coworker and a new designer at your company, as you mentioned. If you have any specific questions about Shirley or need assistance related to her, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# Shirley 에 대한 질문\n",
    "# conversation_with_kg.memory.load_memory_variables({\"input\": \"who is Shirley?\"})\n",
    "\n",
    "response = conversation_with_kg.invoke(\n",
    "    {\"input\": \"Who is Shirley?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"session1\"}}\n",
    ")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-SGRq4Tjy-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
